{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Objective\n","\n","- Create agents that are augmentations of LLMs with functions as tools to achieve business objectives.\n","- Understand how to create function calling agents using `langchain`.\n"],"metadata":{"id":"4GkzUHM3FQwJ"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"ndr74jHUFdc7"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"tgT4ONzOGUeZ"}},{"cell_type":"code","source":["! pip install -q openai==1.55.3 \\\n","                 langchain==0.3.7 \\\n","                 langchain-openai==0.2.9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmmJIO9MGVlD","executionInfo":{"status":"ok","timestamp":1737369613121,"user_tz":-330,"elapsed":19333,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"d14ffe8a-e919-4ea3-fc49-512cb7c51990"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/389.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m389.1/389.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/311.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"_OnTJkUkHbrq"}},{"cell_type":"code","source":["import os\n","import json\n","import requests\n","\n","import pandas as pd\n","\n","from langchain_core.tools import tool\n","from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n","\n","from langchain_openai import AzureChatOpenAI"],"metadata":{"id":"TRQns0JuHc9F","executionInfo":{"status":"ok","timestamp":1737369618749,"user_tz":-330,"elapsed":5631,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["with open('config-azure.json') as f:\n","    configs = f.read()"],"metadata":{"id":"80eAGQ6mNLV5","executionInfo":{"status":"ok","timestamp":1737369618749,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["creds = json.loads(configs)"],"metadata":{"id":"vc6kHKG3NVNV","executionInfo":{"status":"ok","timestamp":1737369618749,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["llm = AzureChatOpenAI(\n","    azure_endpoint=creds[\"AZURE_OPENAI_ENDPOINT\"],\n","    api_key=creds[\"AZURE_OPENAI_KEY\"],\n","    api_version=\"2024-02-01\",\n","    model=\"gpt-4o-mini\",\n","    temperature=0\n",")"],"metadata":{"id":"gL6ZF6z4NcUJ","executionInfo":{"status":"ok","timestamp":1737369619416,"user_tz":-330,"elapsed":671,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Wrapping Functions as Tools"],"metadata":{"id":"dnvxyFBoGMtZ"}},{"cell_type":"markdown","source":["## Use Case 1: Responding to customer queries using a database"],"metadata":{"id":"YT81lDt3PnAx"}},{"cell_type":"markdown","source":["Consider that we are a banking company who wants to allow customers to track their transactions. We want to build an AI agent that acts as an interface between customers who ask natural language questions and customer support personnel who want to answer these questions. Behind the scenes, the agent uses a `pandas` dataframe of customer data to provide answers to these questions."],"metadata":{"id":"Pi9t45ssL9qX"}},{"cell_type":"markdown","source":["Let us begin by creating a dataset and attaching a pandas dataframe to it."],"metadata":{"id":"RYEARIRjMSxJ"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"6y_7pF9RARHu","executionInfo":{"status":"ok","timestamp":1737369619416,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"outputs":[],"source":["data = {\n","    'transaction_id': ['T2001', 'T2002', 'T2003', 'T2004', 'T2005'],\n","    'customer_id': ['C004', 'C005', 'C006', 'C007', 'C008'],\n","    'payment_amount': [150.75, 92.50, 115.30, 70.20, 225.40],\n","    'payment_date': ['2023-03-15', '2023-03-16', '2023-03-17', '2023-03-18', '2023-03-19'],\n","    'payment_status': ['Paid', 'Pending', 'Paid', 'Unpaid', 'Paid']\n","}\n","\n","df = pd.DataFrame(data)"]},{"cell_type":"markdown","source":["Le us now define a couple of functions as tools that allow specific queries to be run on the dataframe.\n","\n","The key thing here is that with function calling, we can define the capabilities of the agent very clearly. Increasing the functionality of the agent amounts to increasing the number of functions defined as tools. Function calling ensures that there is determinism in the agents' behavior, which is the strongest point of this approach."],"metadata":{"id":"VXO6q1QkOMAB"}},{"cell_type":"markdown","source":["To define a function as a tool, we use the `@tool` decorator on the function. Two key aspects of the tool definition are: the function docstring and type hints for the arguments. The content of the docstring is used by the LLM attached to the agent in making a decision on which of the functions should be picked given the user input. The type hints of the function allow the LLM to compose function inputs in the correct format."],"metadata":{"id":"G4vD4LNaQm6S"}},{"cell_type":"code","source":["@tool\n","def retrieve_payment_status(transaction_id: str) -> str:\n","    \"\"\"\n","    Get payment status of a transaction\n","    \"\"\"\n","    if transaction_id in df.transaction_id.values:\n","        return json.dumps({'status': df[df.transaction_id == transaction_id].payment_status.item()})\n","    return json.dumps({'error': 'transaction id not found.'})"],"metadata":{"id":"B1bXM7lpOJWh","executionInfo":{"status":"ok","timestamp":1737369647207,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["@tool\n","def retrieve_payment_date(transaction_id: str) -> str:\n","    \"\"\"\n","    Get payment date of a transaction\n","    \"\"\"\n","    if transaction_id in df.transaction_id.values:\n","        return json.dumps({'date': df[df.transaction_id == transaction_id].payment_date.item()})\n","    return json.dumps({'error': 'transaction id not found.'})"],"metadata":{"id":"4Da9EUxSOOf6","executionInfo":{"status":"ok","timestamp":1737369648835,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["The above tools allow the user (the support executive in this case) to retrieve the payment status and/or the payment date for a particular transaction.  "],"metadata":{"id":"WXF-LOIRTUVs"}},{"cell_type":"markdown","source":["With the tools defined, we can now declare these as tools available to the LLM and bind the tools to the LLM to create an agent like so:"],"metadata":{"id":"1CV3MAhTTlkh"}},{"cell_type":"code","source":["available_tools = {\n","    'retrieve_payment_status': retrieve_payment_status,\n","    'retrieve_payment_date': retrieve_payment_date\n","}"],"metadata":{"id":"EevurwLbORIi","executionInfo":{"status":"ok","timestamp":1737369651336,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["llm_with_tools = llm.bind_tools(list(available_tools.values()))"],"metadata":{"id":"RcViJRw5OTBJ","executionInfo":{"status":"ok","timestamp":1737369651719,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Let us now inspect the execution flow of this agent using the following query. We begin by wrapping the query as a `HumanMessage`."],"metadata":{"id":"De-OOQKSOjRc"}},{"cell_type":"code","source":["query = \"When was transaction T2004 executed?\"\n","\n","messages = [HumanMessage(query)]"],"metadata":{"id":"pT0iixEFOUQp","executionInfo":{"status":"ok","timestamp":1737369652749,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["This human message is presented to the agent during invocation as in the code cell below. The key difference here is that the agent does not directly attempt to answer the question. Instead, it identifies the correct tool to be called and composes the function call as expected by the function signature."],"metadata":{"id":"mdxI9CjkUCKT"}},{"cell_type":"code","source":["ai_msg = llm_with_tools.invoke(messages)\n","messages.append(ai_msg)"],"metadata":{"id":"HSuNcccGOhTc","executionInfo":{"status":"ok","timestamp":1737369654637,"user_tz":-330,"elapsed":706,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["ai_msg.tool_calls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AUHGXflOoaT","executionInfo":{"status":"ok","timestamp":1737369655087,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"fbeda58e-1e66-4c6d-a049-6dd1d5580346"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'name': 'retrieve_payment_date',\n","  'args': {'transaction_id': 'T2004'},\n","  'id': 'call_7t9Mz9m6uHd4KQQodVu2Htgi',\n","  'type': 'tool_call'}]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["As we append the output from the agent at this stage to the messages in the code cell above, notice that the above output has a special role `tool_call`. When an LLM sees this in the message history, it understands which function was called (`retrieve_payment_date` in this case) and what the arguments for the function were."],"metadata":{"id":"74G_obxzUleu"}},{"cell_type":"markdown","source":["Another key thing to note is that the LLM does not execute the function call identified in the `tool_call` by itself. However, since the tool selected is among the boquet of tools declared earlier (`available_tools`), we can extract the tool calls as identified in the list above and invoke the tool with the arguments identified by the LLM."],"metadata":{"id":"l_Y-MULFVU4A"}},{"cell_type":"code","source":["for tool_call in ai_msg.tool_calls:\n","    selected_tool = available_tools[tool_call[\"name\"].lower()]\n","    tool_output = selected_tool.invoke(tool_call[\"args\"])\n","    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"],"metadata":{"id":"SEpdwO__OnSF","executionInfo":{"status":"ok","timestamp":1737369658186,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["In the above code, we are identifying the functions in the tool calls, obtaining their outpts by executing the functions and appending the tool outputs back to the running list of messages."],"metadata":{"id":"2mfMmdNdVtpj"}},{"cell_type":"code","source":["len(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_tGJGwuO4Fr","executionInfo":{"status":"ok","timestamp":1737369659820,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"05d5cac9-3ec4-48e6-f8bf-64e69e23d634"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["At this stage the message chain has the original `HumanMessage`, the `AIMessage` that has the tool call (not the output) and the `ToolMessage` that hosts the output from the tool call. Let us inspect the tool output."],"metadata":{"id":"YFE7TZqDV5zf"}},{"cell_type":"code","source":["messages[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_z37hBBlPREb","executionInfo":{"status":"ok","timestamp":1737369662220,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"a717ec0c-3943-4ca3-c764-a5fc16772e8e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ToolMessage(content='{\"date\": \"2023-03-18\"}', tool_call_id='call_7t9Mz9m6uHd4KQQodVu2Htgi')"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["The output above indicates that the tool execution returned the data to be 2021-10-05. With this chain of messages the LLM can now give an answer to the original question. Notice how we are using the LLM here instead of the LLM with tools."],"metadata":{"id":"WgdlTN0LWigI"}},{"cell_type":"code","source":["final_response = llm.invoke(messages)\n","\n","print(final_response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulQa2jpQO2zC","executionInfo":{"status":"ok","timestamp":1737369665814,"user_tz":-330,"elapsed":497,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"67d3c7bb-b411-4703-b7b7-a1bb01c72ae9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Transaction T2004 was executed on March 18, 2023.\n"]}]},{"cell_type":"markdown","source":["The code snippet below presents an overall execution of this workflow for few different queries."],"metadata":{"id":"-W7s6Vl2WuQ3"}},{"cell_type":"code","source":["def agent_response(query, llm, llm_with_tools):\n","\n","    messages = [HumanMessage(query)]\n","\n","    ai_msg = llm_with_tools.invoke(messages)\n","\n","    messages.append(ai_msg)\n","\n","    for tool_call in ai_msg.tool_calls:\n","        selected_tool = available_tools[tool_call[\"name\"].lower()]\n","        tool_output = selected_tool.invoke(tool_call[\"args\"])\n","        messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n","\n","    final_response = llm.invoke(messages)\n","\n","    return final_response.content"],"metadata":{"id":"fqXIpw9LXV9Q","executionInfo":{"status":"ok","timestamp":1737369665814,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["query = \"What is the status of transaction T2005?\"\n","print(agent_response(query, llm, llm_with_tools))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScYKqkouWzmw","executionInfo":{"status":"ok","timestamp":1737369667199,"user_tz":-330,"elapsed":873,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"5afde037-fc2f-4175-adb6-de3310967441"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["The status of transaction T2005 is \"Paid.\"\n"]}]},{"cell_type":"code","source":["query = \"What is the status of transactions T2005 and T2002?\"\n","print(agent_response(query, llm, llm_with_tools))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrIYpli2W5aF","executionInfo":{"status":"ok","timestamp":1737369673605,"user_tz":-330,"elapsed":6408,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"43cec62d-68b8-44dc-9768-3ba1a3c15cf4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["The status of the transactions is as follows:\n","- Transaction T2005: Paid\n","- Transaction T2002: Pending\n"]}]},{"cell_type":"markdown","source":["While it is good to distinguish the tool calling agent from the main LLM that is answering queries, invoking the agent (i.e., LLM + tools) also gets us to the final answer."],"metadata":{"id":"SE7UZ0wSYELc"}},{"cell_type":"code","source":["query = \"What is the status of transaction T2005?\"\n","print(agent_response(query, llm_with_tools, llm_with_tools))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KW2gfhi6X7Vs","executionInfo":{"status":"ok","timestamp":1737369674279,"user_tz":-330,"elapsed":678,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"23a624e8-99d0-49ec-942c-12780e3a6cff"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["The status of transaction T2005 is \"Paid.\"\n"]}]},{"cell_type":"code","source":["query = \"What is the status of transactions T2005 and T2002?\"\n","print(agent_response(query, llm_with_tools, llm_with_tools))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlXKWQYcYHKm","executionInfo":{"status":"ok","timestamp":1737369675696,"user_tz":-330,"elapsed":1420,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"c7b67f61-c296-4c0a-d275-5e67a53418f2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["The status of the transactions is as follows:\n","- Transaction T2005: **Paid**\n","- Transaction T2002: **Pending**\n"]}]},{"cell_type":"markdown","source":["Like we noted before a strength of the function calling approach is determinism. The capability of the agent is restricted to a pre-defined set of functions. The agent's behavior is restricted to the functions it can execute and hence there is a good amount of control."],"metadata":{"id":"0j7QEszvYZzH"}},{"cell_type":"code","source":["query = \"Change the status of transaction T2002 to 'Paid'\"\n","print(agent_response(query, llm, llm_with_tools))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaYPz642YmqC","executionInfo":{"status":"ok","timestamp":1737369676774,"user_tz":-330,"elapsed":1082,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"1c78b780-4374-4417-c78a-2e6aa0cfabfe"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["I currently don't have the capability to change the status of transactions. However, I can help you retrieve the payment status or payment date of the transaction T2002 if you need that information. Would you like me to do that?\n"]}]},{"cell_type":"markdown","source":["## Use Case 2: API Calls Wrapped as Functions"],"metadata":{"id":"BPt63R-cPsNb"}},{"cell_type":"markdown","source":["An interesting application of function calling is its usage in wrapping APIs. Consider the example of a customer-facing business that invested significant effort in building an emotion classifer and a toxicity classifier. These are in-house models developed by the data science team trained on proprietary data. By hosting these models on company servers and exposing API access, these models effectively become tools for an agent.\n","\n","As an example, let us build an agent that calls models hosted on HuggingFace based on the input received to achieve the objective listed in user instructions.\n","\n","An extension of this approach is that any machine learning model can be converted into a function call and presented as a tool to an agent to choose from."],"metadata":{"id":"5Eod95fJY9_Y"}},{"cell_type":"code","source":["with open('config-hf.json') as f:\n","    hf_configs = f.read()\n","\n","hf_creds = json.loads(hf_configs)"],"metadata":{"id":"bGaVf2mpQClq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the two tool definitions presented below, we take the text presented by the LLM as an input, call the API hosted on a specific URL and return the answer back. Since these are external APIs, a simple error handling mechanism is implemented."],"metadata":{"id":"cspDjhkzaD2Y"}},{"cell_type":"code","source":["@tool\n","def assign_emotion(input: str) -> str:\n","    \"\"\"\"\n","    Assign emotion associated with an input text\n","    \"\"\"\n","\n","    API_URL = \"https://api-inference.huggingface.co/models/michellejieli/emotion_text_classifier\"\n","    hf_key = hf_creds[\"HUGGINGFACE_API_KEY\"]\n","    headers = {\"Authorization\": f\"Bearer {hf_key}\"}\n","    payload = {\n","        \"inputs\": input\n","    }\n","    response = requests.post(API_URL, headers=headers, json=payload)\n","    try:\n","        final_emotion = response.json()[0][0]['label']\n","    except Exception as e:\n","        print(e)\n","        final_emotion = 'neutral'\n","\n","    return final_emotion\n"],"metadata":{"id":"R2ZEWik4Pb_J","executionInfo":{"status":"ok","timestamp":1737370720544,"user_tz":-330,"elapsed":425,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["@tool\n","def detect_toxicity(input: str) -> str:\n","    \"\"\"\"\n","    Detect if the input text is toxic or neutral.\n","    \"\"\"\n","\n","    API_URL = \"https://api-inference.huggingface.co/models/s-nlp/roberta_toxicity_classifier\"\n","    hf_key = hf_creds[\"HUGGINGFACE_API_KEY\"]\n","    headers = {\"Authorization\": f\"Bearer {hf_key}\"}\n","    payload = {\n","        \"inputs\": input\n","    }\n","    response = requests.post(API_URL, headers=headers, json=payload)\n","    try:\n","        final_label = response.json()[0][0]['label']\n","    except Exception as e:\n","        print(e)\n","        final_label = 'neutral'\n","\n","    return final_label"],"metadata":{"id":"DlhEKmvFQsV7","executionInfo":{"status":"ok","timestamp":1737370730194,"user_tz":-330,"elapsed":803,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["With these tools defined, we can bind them to the LLM and create a nenw agent exactly like we did in the previous section."],"metadata":{"id":"g4EfqsXfarGz"}},{"cell_type":"code","source":["available_tools = {\n","    'assign_emotion': assign_emotion,\n","    'detect_toxicity': detect_toxicity\n","}\n","\n","llm_with_tools = llm.bind_tools(list(available_tools.values()))"],"metadata":{"id":"JuBGusZHQShz","executionInfo":{"status":"ok","timestamp":1737370734979,"user_tz":-330,"elapsed":739,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def answer(query):\n","\n","    messages = [\n","        SystemMessage(\n","            \"\"\"\n","            Answer only with the output from tools.\n","            Note that the tool choice is optional.\n","            If answer is not available in the tool output say 'I don't know'.\n","            If the user queries cannot be answered with the tools available say 'I don't know'.\n","            \"\"\"\n","        ),\n","        HumanMessage(query)\n","    ]\n","\n","    ai_msg = llm_with_tools.invoke(messages)\n","    messages.append(ai_msg)\n","\n","    for tool_call in ai_msg.tool_calls:\n","        selected_tool = available_tools[tool_call[\"name\"].lower()]\n","        tool_output = selected_tool.invoke(tool_call[\"args\"])\n","        messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n","\n","    final_response = llm.invoke(messages)\n","\n","    return final_response.content"],"metadata":{"id":"BKmWtJUIQhDr","executionInfo":{"status":"ok","timestamp":1737370734980,"user_tz":-330,"elapsed":13,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["Let us now test our API-calling agent with a few inputs (since these are APIs hosted on free HuggingFace servers, expect errors in execution; multiple runs might be required.)"],"metadata":{"id":"aIJxEHomaxDw"}},{"cell_type":"code","source":["# Tests\n","## 1\n","query = \"Is there a hint of sadness in this review? Review: The movie made me feel very sad.\"\n","response = answer(query)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uVHiMJuQxE_","executionInfo":{"status":"ok","timestamp":1737370737648,"user_tz":-330,"elapsed":1991,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"7598b8ca-fa6e-42d9-9c10-bd557c361c0d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","0\n","I don't know.\n"]}]},{"cell_type":"code","source":["## 2\n","query = \"Is the following message toxic? Message: This is a cruel, cruel world\"\n","response = answer(query)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjBA3Y83Q5Dj","executionInfo":{"status":"ok","timestamp":1737370739619,"user_tz":-330,"elapsed":1974,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"2e2c9b98-e6a9-4930-bc79-4c5a4ef60c47"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","The message is not toxic.\n"]}]},{"cell_type":"code","source":["## 3\n","query = \"Which of 12 * 14 and 14+1000 is the larger number?\"\n","response = answer(query)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM4UnQ7uQ6rw","executionInfo":{"status":"ok","timestamp":1737370748117,"user_tz":-330,"elapsed":1284,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"0506ba1f-9908-4158-f573-5969b19bd328"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["I don't know.\n"]}]},{"cell_type":"code","source":["## 4\n","query = \"\"\"\n","Assign sentiment to the following review.\n","Before assigning sentiment, please check first if the message is toxic.\n","If the message is detected to be toxic then do not assign sentiment but say 'Sorry, cannot help you on that'.\n","Review: This is a cruel, cruel world.\n","\"\"\"\n","\n","response = answer(query)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McOndO8MK7DP","executionInfo":{"status":"ok","timestamp":1737370753110,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Gomtesh Jain","userId":"01434036086632544311"}},"outputId":"cfb5fbb8-9be8-4e46-c995-52d2800d8ab4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["The sentiment of the review is negative.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ffeoI-aFXc9l"},"execution_count":null,"outputs":[]}]}